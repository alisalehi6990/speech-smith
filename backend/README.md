# Speech Smith Backend

This is the backend for **Speech Smith**â€”a fully offline, AI-powered conversational data extraction engine. It powers the conversational form by managing sessions, extracting fields using a local LLM (Llama3), and transcribing audio with Whisperâ€”all running locally for maximum privacy.

## âœ¨ Features
- Local LLM (Llama3) for smart, context-aware question generation and field extraction
- Whisper for speech-to-text, running locally (no cloud APIs)
- Session management for multi-turn conversations
- REST API for frontend integration
- 100% offline: No data leaves your machine

## ğŸ› ï¸ API Endpoints
- `POST /api/conversation/start` â€“ Start a new conversation with a list of required fields
- `POST /api/conversation/answer` â€“ Submit an answer and get the next question or completion
- `POST /api/process` â€“ Upload audio and extract fields in one step

See `swagger.js` for full API documentation.

## ğŸ—ï¸ Architecture
- Node.js/Express server
- Integrates with local Llama3 and Whisper via Docker
- Modular services for conversation, audio, and session management

## ğŸš€ Running Locally

```bash
cd backend
npm install
npm run dev
```

- The backend runs at [http://localhost:3001](http://localhost:3001)
- Requires Llama3 and Whisper services (see Docker Compose in project root)

## ğŸ§ª Running Tests

```bash
npm test
```

## ğŸ¤ Contributing
Pull requests and issues are welcome!

---

**Author:** Ali Salehi  
[GitHub: alisalehi6990](https://github.com/alisalehi6990) 